{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6095676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "import time\n",
    "import torch\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from CoExBO._utils import TensorManager\n",
    "tm = TensorManager()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "n_dims = 6                        # number of dimensions\n",
    "dataset = \"ranger\"\n",
    "seed = 3            # random seed for reproduce the results #SEED 8 rpart_preproc, SEED 3 for Ranger, SEED 1 for rpart, rpart_val: 5,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6223d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Benchmark():\n",
    "    def __init__(self, X_data, Y_data):\n",
    "        self.X_data = X_data\n",
    "        self.Y_data = Y_data\n",
    "        \n",
    "    def find_closest_point(self, query, loop = False):\n",
    "        y_set = []\n",
    "        query = query.squeeze()\n",
    "        if len(query.shape) > 1:\n",
    "            for X in query:\n",
    "                X = X.detach().numpy()\n",
    "                distances = np.linalg.norm(self.X_data - X, axis=1)\n",
    "                closest_index = np.argmin(distances)\n",
    "                #print(self.X_data[closest_index])\n",
    "                #print(X)\n",
    "                y = self.Y_data[closest_index]\n",
    "                y_set.append(y)\n",
    "            #print(\"y_set: \", y_set)\n",
    "            return torch.tensor(y_set, dtype=torch.float32).squeeze()\n",
    "        else:\n",
    "            X = query.detach().numpy()\n",
    "            distances = np.linalg.norm(self.X_data - X, axis=1)\n",
    "            closest_index = np.argmin(distances)\n",
    "            y = self.Y_data[closest_index]\n",
    "            return torch.tensor(y, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b18edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_limit = 0\n",
    "upper_limit = 1\n",
    "colour_map = 'summer'\n",
    "resolution = 200\n",
    "ground_truth = torch.tensor([-1.02543108, -1.02543108])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b24407",
   "metadata": {},
   "source": [
    "## 2. Define domain\n",
    "Next, we define the domain of interest.\n",
    "We set domain as uniform distribution bounded -2 from 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbafa1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# set bounds\n",
    "\n",
    "mins = lower_limit * torch.ones(n_dims)\n",
    "maxs = upper_limit * torch.ones(n_dims)\n",
    "bounds = torch.vstack([mins, maxs]) # bounds\n",
    "\n",
    "# set domain\n",
    "from CoExBO._prior import Uniform    # Import prior from SOBER libraries\n",
    "domain = Uniform(bounds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87eb557",
   "metadata": {},
   "source": [
    "## 3. Preferential learning\n",
    "Next, we try to learn the prior knowledge of human user.<br>\n",
    "For simplicity, human selection process is automatically generated with 60% accuracy via simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e81240d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from CoExBO._coexbo import CoExBOwithSimulation, StateManager\n",
    "n_init_pref = 100      # number of initial random samples for preferential learning\n",
    "n_init_obj = 1        # number of initial random samples for objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb3d21",
   "metadata": {},
   "source": [
    "## 4. Run CoExBO\n",
    "Now, we will collaborate with BO for faster convergence.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b70b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 50     # number of iterations\n",
    "# initial setting\n",
    "torch.manual_seed(seed)\n",
    "state = StateManager(n_dims=n_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ee82e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "def load_module(filename):\n",
    "    module_name = os.path.splitext(os.path.basename(filename))[0]\n",
    "    return SourceFileLoader(module_name, filename).load_module(module_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90abdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TNPA(\n",
       "  (embedder): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=64, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (predictor): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "model_type = 'tnpa'\n",
    "model_cls = getattr(load_module(f'./models/{model_type}.py'), model_type.upper())\n",
    "with open(f'configs/{dataset}/{model_type}.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "#if args.model in [\"np\", \"anp\", \"cnp\", \"canp\", \"bnp\", \"banp\", \"tnpa\", \"tnpd\", \"tnpnd\"]:\n",
    "model = model_cls(**config)\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e83e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from botorch.acquisition import AnalyticAcquisitionFunction\n",
    "from botorch.utils import t_batch_mode_transform\n",
    "from CoExBO._utils import TensorManager\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "results_path = './results/'\n",
    "model_name = 'tnpa'\n",
    "ckpt_path = osp.join(results_path, dataset, model_name, 'ckpt.tar')\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45c8641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_test = np.load(f'./datasets/{dataset}/X_test.npz')\n",
    "y_test = np.load(f'./datasets/{dataset}/y_test.npz')\n",
    "X_validation = np.load(f'./datasets/{dataset}/X_validation.npz')\n",
    "y_validation = np.load(f'./datasets/{dataset}/y_validation.npz')\n",
    "\n",
    "X_validation_ = np.array([X_validation[key].astype('float32') for key in X_validation.keys()])\n",
    "y_validation_ = np.array([y_validation[key].astype('float32') for key in y_validation.keys()])\n",
    "\n",
    "\n",
    "X_test_ = np.array([X_test[key].astype('float32') for key in X_test.keys()])\n",
    "y_test_ = np.array([y_test[key].astype('float32') for key in y_test.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ccb51e84",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_validation_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mType\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'Type'"
     ]
    }
   ],
   "source": [
    "X_validation_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3addcce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 115 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.xc.shape:  torch.Size([1, 1, 6])\n",
      "MEAN SHAPE:  torch.Size([115])\n",
      "DATA1 : [[0.0043 0.1056 0.2858 0.027  0.4716 0.0601]]\n",
      "self.xc.shape:  torch.Size([1, 1, 6])\n",
      "MEAN SHAPE:  torch.Size([1])\n",
      "self.xc.shape:  torch.Size([1, 1, 6])\n",
      "MEAN SHAPE:  torch.Size([7130])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "xt = torch.tensor([[0.0043, 0.1056, 0.2858, 0.0270, 0.4716, 0.0601],[0.0043, 0.1056, 0.2858, 0.0270, 0.4716, 0.0601],[0.0043, 0.1056, 0.2858, 0.0270, 0.4716, 0.0601],[0.0043, 0.1056, 0.2858, 0.0270, 0.4716, 0.0601]]).cuda()\n",
    "model.xc = torch.tensor([[[0,0,0,0,0,0]]]).cuda()\n",
    "model.yc = torch.tensor([[[0]]]).cuda()\n",
    "explainer = shap.KernelExplainer(model.predict_mean, X_validation_[0])\n",
    "mean_shap = explainer.shap_values(xt[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dbb9726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 6 artists>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(mean_shap)),mean_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5869176f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 115 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEAN SHAPE:  torch.Size([115])\n",
      "DATA1 : [[0.0043 0.1056 0.2858 0.027  0.4716 0.0601]]\n",
      "MEAN SHAPE:  torch.Size([1])\n",
      "MEAN SHAPE:  torch.Size([7130])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2.27804028e-03,  3.42092922e-05,  1.04051838e-03, -3.27963624e-04,\n",
       "        3.48472083e-04,  1.04075380e-03])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explainer = shap.KernelExplainer(model.predict_std, X_validation_[0])\n",
    "explainer.shap_values(xt[0].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed9dfed0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359e360b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_VAL:  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0043, 0.1056, 0.2858, 0.0270, 0.4716, 0.0601]])\n",
      "0) parameters: beta 1.697e+00 gamma 0.000e+00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m beta, gamma \u001b[38;5;241m=\u001b[39m state(t)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#print(\"dataset_obj: \", dataset_obj[1])\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m result, dataset_obj, dataset_duel \u001b[38;5;241m=\u001b[39m \u001b[43mcoexbo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_duel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_TPN\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlower_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlower_limit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupper_limit\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m best_v \u001b[38;5;241m=\u001b[39m dataset_obj[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_v \u001b[38;5;241m>\u001b[39m max_bv:\n",
      "File \u001b[0;32m/lustre/lunari/NPF/CoExBO-meta/CoExBO/_coexbo.py:658\u001b[0m, in \u001b[0;36mCoExBOwithSimulation.__call__\u001b[0;34m(self, dataset_obj, dataset_duel, beta, gamma, sigma, model_TPN, lower_limit, upper_limit)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# 1. CoExBO loop\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_preference:\n\u001b[0;32m--> 658\u001b[0m     model, prior_pref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_pairwise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pairwise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_TPN:\n\u001b[1;32m    660\u001b[0m         model \u001b[38;5;241m=\u001b[39m model_TPN\n",
      "File \u001b[0;32m/lustre/lunari/NPF/CoExBO-meta/CoExBO/_coexbo.py:514\u001b[0m, in \u001b[0;36mCoExBOwithSimulation.set_models\u001b[0;34m(self, X, Y, X_pairwise, y_pairwise)\u001b[0m\n\u001b[1;32m    511\u001b[0m model \u001b[38;5;241m=\u001b[39m set_and_fit_rbf_model(X, Y)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearn_preference:\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;66;03m# CoExBO acquisition function is to learn human preference.\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m     model_pref \u001b[38;5;241m=\u001b[39m \u001b[43mset_and_train_classifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_pairwise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pairwise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    519\u001b[0m     prior_pref \u001b[38;5;241m=\u001b[39m MonteCarloQuadrature(model_pref, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain, n_mc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_mc_quadrature)\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, prior_pref\n",
      "File \u001b[0;32m/lustre/lunari/NPF/CoExBO-meta/CoExBO/_gp_classifier.py:105\u001b[0m, in \u001b[0;36mset_and_train_classifier\u001b[0;34m(X_pairwise, y_pairwise, training_iter)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;124;03mSet and Train the Dirichlet GP model in one go.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m- model: gpytorch.models, the Dirichlet GP model after training\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    104\u001b[0m model \u001b[38;5;241m=\u001b[39m set_gp_classifier(X_pairwise, y_pairwise)\n\u001b[0;32m--> 105\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_by_sgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/lustre/lunari/NPF/CoExBO-meta/CoExBO/_gp_classifier.py:88\u001b[0m, in \u001b[0;36mtrain_by_sgd\u001b[0;34m(model, training_iter)\u001b[0m\n\u001b[1;32m     86\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(train_x)\n\u001b[1;32m     87\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmll(output, model\u001b[38;5;241m.\u001b[39mlikelihood\u001b[38;5;241m.\u001b[39mtransformed_targets)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 88\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/hnap/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/hnap/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = []\n",
    "import numpy as np\n",
    "meta = True\n",
    "\n",
    "X_test = np.load(f'./datasets/{dataset}/X_test.npz')\n",
    "y_test = np.load(f'./datasets/{dataset}/y_test.npz')\n",
    "X_validation = np.load(f'./datasets/{dataset}/X_validation.npz')\n",
    "y_validation = np.load(f'./datasets/{dataset}/y_validation.npz')\n",
    "\n",
    "X_validation_ = np.array([X_validation[key].astype('float32') for key in X_validation.keys()])\n",
    "y_validation_ = np.array([y_validation[key].astype('float32') for key in y_validation.keys()])\n",
    "\n",
    "\n",
    "X_test_ = np.array([X_test[key].astype('float32') for key in X_test.keys()])\n",
    "y_test_ = np.array([y_test[key].astype('float32') for key in y_test.keys()])\n",
    "\n",
    "best_values = []\n",
    "total_trajectories = []\n",
    "for i in range(len(X_test)):\n",
    "    \n",
    "    torch.random.manual_seed(seed)\n",
    "    benchmark = Benchmark(X_test_[i], y_test_[i])\n",
    "    # print(y_test[i])\n",
    "    benchmark2 = Benchmark(X_validation_[i], X_validation_[i])\n",
    "    true_function = benchmark.find_closest_point\n",
    "\n",
    "    x_val = torch.rand(1, n_dims)\n",
    "    print(\"X_VAL: \", x_val)\n",
    "    y_val = true_function(x_val)\n",
    "    dataset_obj = (x_val,y_val)\n",
    "    \n",
    "    true_function2 = benchmark.find_closest_point\n",
    "    coexbo = CoExBOwithSimulation(domain, true_function, sigma=0.5, hallucinate=False, meta = meta)\n",
    "    coexbo2 = CoExBOwithSimulation(domain, true_function2, sigma=0.5, hallucinate=False, meta = meta)\n",
    "    #dataset_obj, _ = coexbo.initial_sampling(n_init_obj, n_init_pref)\n",
    "    _, dataset_duel = coexbo.initial_sampling(n_init_obj, n_init_pref)\n",
    "    \n",
    "    # print(\"dataset_duel: \", dataset_duel)\n",
    "    #print(dataset_duel)\n",
    "    #_, dataset_duel = coexbo.initial_sampling(n_init_obj, n_init_pref)\n",
    "    max_bv = -1\n",
    "    trajectory = [y_val]\n",
    "    for t in range(n_iterations):\n",
    "        beta, gamma = state(t)\n",
    "        #print(\"dataset_obj: \", dataset_obj[1])\n",
    "        result, dataset_obj, dataset_duel = coexbo(\n",
    "            dataset_obj, dataset_duel, beta, gamma, model_TPN = model, lower_limit= lower_limit, upper_limit=upper_limit\n",
    "        )\n",
    "        best_v = dataset_obj[1].max().item()\n",
    "        if best_v > max_bv:\n",
    "            max_bv = best_v\n",
    "        trajectory.append(max_bv)\n",
    "        print(\"Trajectory: \", trajectory)\n",
    "        #print(f\"{len(dataset_obj[0])}) Best value: {best_v:.5e}\")\n",
    "        results.append(result)\n",
    "    total_trajectories.append(dataset_obj[1].detach().cpu().numpy())\n",
    "    best_values.append(trajectory)\n",
    "results = torch.tensor(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b4bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save the object as a pickle file\n",
    "with open(f'evaluations/meta_{dataset}_3.pkl', 'wb') as file:\n",
    "    pickle.dump(total_trajectories, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b615b72",
   "metadata": {},
   "source": [
    "# Results\n",
    "[overhead(s), best observation, Euclidean distance between the pairwise candidates, correct_answer_rate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260c915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([0.1547]),\n",
       "  0.5535723567008972,\n",
       "  0.5535723567008972,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796,\n",
       "  0.6778167486190796],\n",
       " [tensor([0.0727]),\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431,\n",
       "  0.6181818246841431],\n",
       " [tensor([0.5730]),\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " [tensor([0.]),\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759,\n",
       "  0.9444736838340759],\n",
       " [tensor([0.6989]),\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894,\n",
       "  0.921507716178894],\n",
       " [tensor([0.9673]),\n",
       "  0.9672895073890686,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454,\n",
       "  0.9766367077827454]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3c76eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
